-- phpMyAdmin SQL Dump
-- version 4.7.0
-- https://www.phpmyadmin.net/
--
-- Hôte : localhost
-- Généré le :  mar. 01 jan. 2019 à 20:43
-- Version du serveur :  10.1.22-MariaDB
-- Version de PHP :  7.1.4

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET AUTOCOMMIT = 0;
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Base de données :  `dsti_cms`
--

-- --------------------------------------------------------

--
-- Structure de la table `admin_users`
--

CREATE TABLE `admin_users` (
  `user_id` int(11) NOT NULL,
  `user_name` varchar(100) NOT NULL,
  `user_password` varchar(100) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Déchargement des données de la table `admin_users`
--

INSERT INTO `admin_users` (`user_id`, `user_name`, `user_password`) VALUES
(1, 'admin', 'admin'),
(2, 'dsti', 'dsti');

-- --------------------------------------------------------

--
-- Structure de la table `categories`
--

CREATE TABLE `categories` (
  `cat_id` int(11) NOT NULL,
  `cat_title` varchar(100) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Déchargement des données de la table `categories`
--

INSERT INTO `categories` (`cat_id`, `cat_title`) VALUES
(1, 'DSTI'),
(2, 'Artifical Intelligence'),
(3, 'Machine Learning'),
(4, 'Deep Learning'),
(5, 'Data Science'),
(6, 'FAceBook');

-- --------------------------------------------------------

--
-- Structure de la table `comments`
--

CREATE TABLE `comments` (
  `comment_id` int(11) NOT NULL,
  `post_id` int(11) NOT NULL,
  `comment_name` varchar(50) NOT NULL,
  `comment_email` varchar(100) NOT NULL,
  `comment_text` text NOT NULL,
  `status` text NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Déchargement des données de la table `comments`
--

INSERT INTO `comments` (`comment_id`, `post_id`, `comment_name`, `comment_email`, `comment_text`, `status`) VALUES
(3, 1, 'Benya Jamiu', 'shafiiyah1@gmail.com', 'This is testing from Benya Jamiu', 'unapprove'),
(5, 7, 'Rasheed Benya', 'rasheed@gmail.com', 'This information is very nice and try to keep it up', 'unapprove'),
(6, 7, 'Bob Keel', 'lawkeen@hotmail.com', 'In 21st century AI will take all the hard jobs', 'approve'),
(7, 5, 'James Rasaki', 'jamiu@yahoo.com', 'We need Machine learning to make jobs so easy and smooth', 'unapprove'),
(8, 5, 'Waheed Suraj', 'suraju@hotmail.com', 'This is very nice application for us..', 'unapprove'),
(9, 5, 'Waheed Suraj', 'suraju@hotmail.com', 'This is very nice application for us..', 'unapprove'),
(10, 5, 'Waheed Suraj', 'suraju@hotmail.com', 'This is very nice application for us..', 'approve'),
(11, 5, 'Wale Kamaruden', 'wala@yahoo.com', ' However, sometimes it is desirable to be able to generate synthetic data based on complex nonlinear symbolic input, and we discussed one such method. Furthermore.\r\n  we also discussed a exciting Python library which can generate random real-life datasets for database skill practice and analysis tasks.', 'approve'),
(12, 12, 'Bob Keel', 'lawkeen@hotmail.com', 'Its nice article from MIT about AI', 'unapprove'),
(13, 1, 'Benya Jamiu', 'shafiiyah1@gmail.com', 'hahahahahahahhahahaha', 'unapprove');

-- --------------------------------------------------------

--
-- Structure de la table `posts`
--

CREATE TABLE `posts` (
  `post_id` int(11) NOT NULL,
  `category_id` int(11) NOT NULL,
  `post_title` varchar(100) NOT NULL,
  `post_date` text NOT NULL,
  `post_author` varchar(50) NOT NULL,
  `post_keywords` text NOT NULL,
  `post_image` text NOT NULL,
  `post_content` text NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Déchargement des données de la table `posts`
--

INSERT INTO `posts` (`post_id`, `category_id`, `post_title`, `post_date`, `post_author`, `post_keywords`, `post_image`, `post_content`) VALUES
(1, 6, 'Automated machine learning: a different notion of deep2', '2018-12-25', 'Elena Nisioti1', 'machine-human2,AutoML,Programming Language, Machine Learning, Deep Learning, AI, ML, DL, DS, Data Science, DSTI', 'dsti5.png', '  \"Computer programming is about automation, and machine learning is all about automating automation. Then, automated machine learning is the automation of automating automation.\"3\r\n\r\n    ï¿½ Sebastian Rashka\r\n\r\nAutomated machine learning has been under the AI radar for a couple of years now. Although large companies like Amazon and Google have already launched their AutoML tools, the AutoML workshop of ICML has attracted significant interest and research makes significant steps towards understanding the nature of machine learning problems, AutoML is still a niche term, reserved for the avant-garde of the data science community.\r\n\r\nPossibly overshadowed by the deep learning frenzy, evidently not mature enough to dazzle us with applications, AutoML has not yet been understood or clearly defined. A next step into the human-machine relationship? A deeper level of understanding of artificial intelligence?\r\n\r\nImportant discoveries are usually acknowledged ex post, as society needs to experience, understand and evaluate them. Especially when it comes to AI, itï¿½s easy to miss the forest for the trees, as things are going deeper?ï¿½?but deeper towards which direction?\r\n\r\nWhat isï¿½AutoML?\r\n\r\n1. Inserting more automation in training a machine learning model.\r\n\r\nWait, isnï¿½t a machine learning model already automatically trained? Partly yes, and this is why we call it machine learning, because the algorithms ï¿½learnï¿½ by themselves, based on the data we give to them. However, the most tedious, time-consuming tasks, the ones that are traditionally undervalued when publishing amazing results, have nothing to do with the actual training of the model.\r\n\r\nIt is a realization of anyone involved with a machine learning experiment that good results are easy to have, but satisfactory results take time, smart design, experience in the field and, quite often, a bit of luck to achieve. The 90% of an experiment Caruana is referring to, is pre-processing, feature extraction, hyper-parameter tuning, algorithm selection, model evaluation and other possible steps of an ML pipeline.\r\n\r\nThe step that AutoML has mainly focused on is hyper-parameter tuning, which in general refers to choosing the optimal values for the hyper-parameters of a learning algorithm that it cannot choose by itself. For example, a neural network learns the optimal weights by itself, but defining the number of layers, the number of neurons and the learning rate is a task, and a most tedious one, for the ML practicioner. As tuning is a well-defined task, it has been a primal target for AutoML toolsï¿½.\r\n\r\nWhy you shouldï¿½care\r\n\r\nAutoML is a brand new tool into the quiver of data scientists. And as all tools, it can be valued, misused or left to rust. As a data scientist, you can choose to use AutoML now as an assistant that will increase your productivity by relieving you from the tedious tasks of pre-processing your data or tuning your models. Or you can invest your time into becoming an AutoML expert and use it as a strategic weapon in the future job market or as a shield against an industry that automates what is trivial, but is still struggling with the nontrivialities of intelligence?ï¿½?artificialï¿½orï¿½not.\r\n\r\nAnd finally, as part of a human society that is consistently developing its relationship with technology, we should bear in mind that the question is not always what we should automate, but can sometimes be: what should we not automate?\r\n\r\n'),
(3, 5, 'DSTI the best DATA SCIENCE School in France', '2018-12-21 22:07:54', 'Paul Peter', 'AI, DL, ML and Data Science, Programming, SQL, AWS, SAS, Amazon', 'dsti1.png', '\r\nWe are driven by only one goal: high value employment for students.\r\n\r\nData ScienceTech Institute is a degree-granting, private postgraduate vocational institution registered with the Rectorat of Nice (UAI 062136P) and the Rectorat of Paris (UAI 0755832G). Rectorats are the regional delegations of the French Ministry for Education, Higher Education and Research.\r\n\r\n  DSTI SINCE 2015   \r\n\r\n Data ScienceTech Institute was created in 2015 on an idea from Sébastien Corniglion and Léo Souquet. As former co-founders of an Information Systems start up targeted for SMEs, they quickly faced difficulties in hiring the right staff. As no one really had the full-width range of skills required for the Big Data world of the XXIst century. With years of experience in the Higher Education world, particularly in France and in the UK, they also had a vision of what worked beautifully and what needed to be changed.\r\n\r\nData ScienceTech Institute was constructed with the world-famous quality and intensity of French science and engineering. And the natural British business savviness and pragmatism on the other. As the project was taking shape, they met José Massol, a very active Business Angel and retired Senior Vice-President of Thales Group. Very attracted by the project, he offered to come in not as a Business Angel but as a partner, and is now our esteemed Chairman.\r\n\r\n  OUR MISSION\r\n\r\nData Science is a complex field, involving computer science, hard science and business applications all surrounded by ethics and law. We train operational Data Scientists by offering the most intensive programmes available to take up the Big Data challenge!\r\n\r\nData Science is also applied science. Our programmes are hence driven by a Scientific Advisory Board, composed of recognised and respected professional figures as well as academics with industrial partnerships experience. In fact, we commit ourselves to follow industrial and job market needs to the letter, so our programmes will evolve on a yearly basis. Therefore, you will be invited to come back, in presence or via e-learning, to keep your skills up-to-date.\r\n\r\nIn that respect, we are quality-assessed using two simple criteria: your employment rate and your employers’ satisfaction. These are even evaluated during the programme, thanks to the projects and junior consulting missions you will undertake.\r\n\r\nAre you a fresh, bright young graduate or an experienced professional? We are totally confident the Data ScienceTech Institute programme you will choose will put all your brain cogs in action and give you the “Sexiest Job of the XXIst century”. (Havard Business Review, Oct. 2012)\r\n\r\n OUR PROGRAMMES\r\n1) APPLIED MSC IN DATA SCIENCE AND AI\r\n2) APPLIED MSC IN DATA ENGINEERING'),
(5, 5, 'Synthetic data generation-a must-have skill for new data scientists', '2018-12-22 10:50:29', 'Tirthajyoti Sarkar', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science', 'nlp1.png', '\r\n Introduction\r\nData is the new oil and truth be told only a few big players have the strongest hold on that currency. Googles and Facebooks of this world are so generous with their latest machine learning algorithms and packages (they give those away freely) because the entry barrier to the world of algorithms is pretty low right now. Open source has come a long way from being christened evil by the likes of Steve Ballmer to being an integral part of Microsoft. And plenty of open source initiatives are propelling the vehicles of data science, digital analytics, and machine learning.\r\n\r\n      â€œStanding in 2018 we can safely say that, algorithm, programming frameworks, and machine learning packages (or even tutorials    \r\n         and courses how to learn these techniques) are not the scarce resource but high-quality data is.â€\r\n\r\nThis often creates a complicated issue for the beginners in data science and machine learning. I faced it myself years back when I started my journey in this path.\r\n\r\nCritical for self-driven dataÂ science\r\nData science is hot and selling. And, people are moving into data science. They are changing careers, paying for boot-camps and online MOOCs, building network on LinkedIn. But many such new entrants face difficulty maintaining the momentum of learning the new trade-craft once they are past the regularized curricula of their course and into uncertain zone.\r\n\r\nWhat kind of data may be needed for a rich learning experience?\r\nImagine you are tinkering with a cool machine learning algorithm like SVM or a deep neural net. What kind of dataset you should practice them on? If you are learning from scratch, the advice is to start with simple, small-scale datasets which you can plot in two dimensions to understand the patterns visually and see for yourself the working of the ML algorithm in an intuitive fashion. For example, here is an excellent article on various datasets you can try at various level of learning.\r\n\r\nYes, it is a possible approach but may not be the most viable or optimal one in terms of time and effort. Good datasets may not be clean or easily obtainable. You may spend much more time looking for, extracting, and wrangling with a suitable dataset than putting that effort to understand the ML algorithm\r\n\r\n   â€œThe experience of searching for a real life dataset, extracting it, running exploratory data analysis, and wrangling with it to make it\r\n     suitably prepared for a machine learning based modeling is invaluable. I am currently working on a course/book just on that topic.â€\r\n\r\nWhat is a synthetic dataset?\r\nAs the name suggests, quite obviously, a synthetic dataset is a repository of data that is generated programmatically. So, it is not collected by any real-life survey or experiment. Its main purpose, therefore, is to be flexible and rich enough to help an ML practitioner conduct fascinating experiments with various classification, regression, and clustering algorithms. Desired properties are,\r\n\r\nData generation with scikit-learn methods\r\nScikit-learn is an amazing Python library for classical machine learning tasks (i.e. if you donâ€™t care about deep learning in particular). However, although its ML algorithms are widely used, what is less appreciated is its offering of cool synthetic data generation functions.\r\n\r\nSummary and conclusion\r\nWe discussed the criticality of having access to high-quality datasets for oneâ€™s journey into the exciting world of data science and machine learning. Often the paucity of flexible and rich enough dataset limits oneâ€™s ability to deep dive into the inner working of a machine learning or statistical modeling technique and leaves the understanding superficial.\r\nSynthetic datasets can help immensely in this regard and there are some ready-made functions available to try this route. However, sometimes it is desirable to be able to generate synthetic data based on complex nonlinear symbolic input, and we discussed one such method.\r\nFurthermore, we also discussed a exciting Python library which can generate random real-life datasets for database skill practice and analysis tasks.'),
(7, 3, 'Machine Learning The Way Out in 21st Century', '2018-12-22 11:40:22', 'Mybridge John ', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science, Jobs, Software, SQL', 'ml6.png', '\r\n  Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\r\n\r\n                       Evolution of machine learning\r\n\r\nBecause of new computing technologies, machine learning today is not like machine learning of the past. It was born from pattern recognition and the theory that computers can learn without being programmed to perform specific tasks; researchers interested in artificial intelligence wanted to see if computers could learn from data.Â The iterative aspect of machine learning is important because as models are exposed to new data, they are able to independently adapt. They learn from previous computations to produce reliable, repeatable decisions and results. Itâ€™s a science thatâ€™s not new â€“ but oneÂ that has gainedÂ fresh momentum.\r\n\r\n\r\nDespite the numbing buzz around artificial intelligence (AI) and machine learning (ML), itâ€™s more than abstract ideas and hypothetical applications. AI and ML are already powering tools that can give your business decision-making processes a massive upgrade. The technology is here, itâ€™s already proving itself in the market, and itâ€™s increasingly being built with business in mind. The myths around artificial intelligence can get pretty dense,so weâ€™ve taken five of the biggest and dissected them to help you understand the truth about todayâ€™s AI landscape. Hereâ€™s what you really need to know.\r\n\r\n\r\nThe automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.'),
(8, 4, ' YOLO object detection with OpenCV', '2018-12-22 11:56:12', 'Adrian Rosebrock', 'Opencv, Object Detection, Deep Learning, Computer Vision, ML, AI, DL', 'dl9.png', '\r\n  \r\nWeâ€™ll start with a brief discussion of the YOLO object detector, including how the object detector works.\r\n\r\nFrom there weâ€™ll use OpenCV, Python, and deep learning to:\r\n\r\n1. Apply the YOLO object detector to images\r\n2. Apply YOLO to video streams\r\n\r\nWeâ€™ll wrap up the tutorial by discussing some of the limitations and drawbacks of the YOLO object detector, including some of my personal tips and suggestions\r\n\r\nIn the rest of this tutorial weâ€™ll:\r\n* Discuss the YOLO object detector model and architecture\r\n* Utilize YOLO to detect objects in images\r\n* Apply YOLO to detect objects in video streams\r\n* Discuss some of the limitations and drawbacks of the YOLO object detector\r\nLetâ€™s dive in!\r\n\r\nWhen it comes to deep learning-based object detection, there are three primary object detectors youâ€™ll encounter:\r\n\r\n* R-CNN and their variants, including the original R-CNN, Fast R- CNN, and Faster R-CNN\r\n* Single Shot Detector (SSDs)\r\n* YOLO\r\n\r\nR-CNNs are one of the first deep learning-based object detectors and are an example of a two-stage detector.\r\n\r\nOn the 156 class version of COCO, YOLO9000 achieved 16% mean Average Precision (mAP), and yes, while YOLO can detect 9,000 separate classes, the accuracy is not quite what we would desire.\r\nRedmon and Farhadi recently published a new YOLO paper, YOLOv3: An Incremental Improvement (2018). YOLOv3 is significantly larger than previous models but is, in my opinion, the best one yet out of the YOLO family of object detectors.\r\nWeâ€™ll be using YOLOv3 in this blog post, in particular, YOLO trained on the COCO dataset.\r\nThe COCO dataset consists of 80 labels, including, but not limited to:\r\n1 People\r\n2 Bicycles\r\n3 Cars and trucks\r\n4 Airplanes\r\n5 Stop signs and fire hydrants\r\n6 Animals, including cats, dogs, birds, horses, cows, and sheep, to name a few\r\n7 Kitchen and dining objects, such as wine glasses, cups, forks, knives, spoons, etc.\r\n  and much more!'),
(9, 3, 'Hands-on Machine Learning Model Interpretation', '2018-12-22 12:03:17', 'Dipanjan (DJ) Sarkar', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science', 'ml4.png', '\r\n A comprehensive guide to interpreting machine learning models\r\n \r\n Introduction\r\n\r\nInterpreting Machine Learning models is no longer a luxury but a necessity given the rapid adoption of AI in the industry. This article in a continuation in my series of articles aimed at â€˜Explainable Artificial Intelligence (XAI)â€™. The idea here is to cut through the hype and enable you with the tools and techniques needed to start interpreting any black box machine learning model. Following are the previous articles in the series in case you want to give them a quick skim (but are not mandatory for this article).\r\n\r\n\r\n* Part 1â€Šâ€”â€ŠThe Importance of Human Interpretable Machine Learningâ€™: which covers the what and why of human interpretable machine learning and the need and importance of model interpretation along with its scope and criteria\r\n\r\n* Part 2 â€”Model Interpretation Strategiesâ€™ which covers the how of human interpretable machine learning where we look at essential concepts pertaining to major strategies for model interpretation.\r\n\r\nIn this article we will give you hands-on guides which showcase various ways to explain potential black-box machine learning models in a model-agnostic way. We will be working on a real-world dataset on Census income, also known as the Adult dataset available in the UCI ML Repository where we will be predicting if the potential income of people is more than $50K/yr or not.\r\n\r\nThe purpose of this article is manifold. The first main objective is to familiarize ourselves with the major state-of-the-art model interpretation frameworks out there (a lot of them being extensions of LIMEâ€Šâ€”â€Šthe original framework and approach proposed for model interpretation which we have covered in detail in Part 2 of this series).\r\n\r\nThe major model interpretation techniques we will be covering in this tutorial include the following.\r\n\r\n* Feature Importances\r\n* Partial Dependence Plots\r\n* Model Prediction Explanations with Local Interpretation\r\n* Building Interpretable Models with Surrogate Tree-based Models\r\n* Model Prediction Explanation with SHAP values\r\n* Dependence & Interaction Plots with SHAP\r\n\r\n\r\n\r\nLoading Necessary Dependencies\r\n\r\nWe will be using a lot of frameworks and tools in this article given it is a hands-on guide to model interpretation. We recommend you to load up the following dependencies to get the maximum out of this guide and follow due process.\r\n\r\nConclusion\r\n\r\nIf you are reading this, I would like to really commend your efforts on going through this huge and comprehensive tutorial on machine learning model interpretation. This article should help you leverage the state-of-the-art tools and techniques which should help you in your journey on the road towards Explanable AI (XAI). Based on the concepts and techniques we learnt in Part 2, in this article, we actually implemented them all on a complex machine learning ensemble model trained on a real-world dataset. I encourage you to try out some of these frameworks with your own models and datasets and explore the world of model interpretation!\r\n\r\n\r\n\r\n   \r\n '),
(10, 1, 'Sophia-Antipolis Campus', '2018-12-22 12:08:42', 'Sebastine and Vincent', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science, Msc Applied Data Science,', 'dsti9.png', '\r\n  In the heart of the largest European Technology cluster!\r\n\r\n OurÂ Sophia-AntipolisÂ campus, which is also DSTI headquarters, sits in the largest European technology cluster, often called theÂ â€œFrench Silicon Valleyâ€. Colloquially calledÂ â€œSophiaâ€, the park hosts R&D units from multi-national companiesÂ (Amadeus, Thales Underwater Systems, Cisco Systems or HPE to name a few), global institutionsÂ (W3C, ETSI)Â and a thriving ecosystem of teachingÂ (UniversitÃ© Nice Sophia-Antipolis, Skema Business School)Â and researchÂ (INRIA, CNRS, INRA).\r\n\r\nSophia is slightly inland fromÂ Antibes, its nearest costal city and is essentially a beautiful pine forest.Â Antibes is our recommended place to stay, as itâ€™s so international that you may sometimes come across someone who speaks French! This is even more true during the spring and summer seasons, with all the boat crews coming from all over the world for a pint in the (in)famousÂ Blue Lady Pub.\r\n\r\nDSTI campus, calledÂ â€œLesÂ Templiersâ€, breathes of IT history: the premises were built by and forÂ Digital Equipment CorporationÂ and after its merger withÂ CompaqÂ and thenÂ Hewlett-Packard, was known to be occupied by both HP and Amadeus. It was also the very first building in the whole park to have a dedicated optic fibre connection in the early 90â€™s. BillÂ Gates is known to have visited there a few times, arriving by helicopter from Nice AirportÂ (the campus does have an heliport)Â during this golden era! Today,Â â€œLesÂ Templiersâ€Â is a multi-tenant building, with DSTI of course but also quite a few IT companies working in the travel industry thanks to the dynamics of the Amadeus ecosystem.\r\n\r\nFew Perks:\r\n\r\n\r\n-> The campus hosts its own canteen, offering a pretty nice three-course meal for 8 euros as well as a snack bar for sandwiches and nibbles. You can also walk accros the road to theÂ â€œEspace Saint-Philippeâ€, with its supermarket, restaurants, delicatessen and a Subway!\r\n\r\n-> You have the whole French Riviera to visit: Cannes, Nice, Monaco to name a few. But also thanks to a unique geography, as well as the beautiful beaches, students are only 1 hour away from 3 skying resorts in the winter,Â ValbergÂ being the nearest and mostÂ â€œhomelyâ€! The wonders of Provence are also by your doorstep. You can visitÂ MarseilleÂ which is located few hours from Sophia. You cannot be in Sophia and not visit theÂ Verdon Gorge, considered one of Europeâ€™s most beautiful river canonÂ (here for a Flickr overview). But why limit yourself to France when theÂ Italian borderÂ and its stunning Riviera is less than one hour away?!\r\n\r\n-> Nearby banking & Accommodation:Â TheÂ â€œEspace Saint-Philippeâ€Â has an international branch of a large European bank where English is spoken and a student residence hall calledÂ â€œThesaâ€, which is affordable and practical for coming to DSTI, if a little quiet.\r\n\r\n-> â€œAnima Sana In Corpore Sanoâ€Â right? Well thereâ€™s a nicely equippedÂ gymÂ in the campus, and itâ€™sÂ freeÂ so no excuse then! Of course, as the typical working week of a DSTI student is made of 50hrs dedicated to science and technology, you still haveÂ â€œplentyâ€Â of opportunities to go to the beach with a nicely chilled bottle of Provence RosÃ© wine and just enjoy being there. For the club lovers,Â NiceÂ is veryÂ (too?)Â lively but donâ€™t discardÂ MonacoÂ too: albeit theÂ â€œnameâ€, itâ€™s sometimes cheaper to go outÂ (in style of course)Â there! And if you are more aÂ â€œmountainâ€Â person, theÂ National Park of MercantourÂ and it wonders can be accessed with a bus starting from NiceÂ (around 1h30 drive).\r\n'),
(11, 2, 'Deep-learning technique reveals \"invisible\"objects in the dark', '2018-12-23 15:54:01', 'Lex Fridman', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science,MIT,Lex Fridman, Andrew Ng, Kears, Theano, FB,Google, Aws,Amazon', 'lex_fridman.png', '\r\n Small imperfections in a wine glass or tiny creases in a contact lens can be tricky to make out, even in good light. In almost total darkness, images of such transparent features or objects are nearly impossible to decipher. But now, engineers at MIT have developed a technique that can reveal these â€œinvisibleâ€ objects, in the dark.\r\n\r\n\r\nIn a study published today in Physical Review Letters, the researchers reconstructed transparent objects from images of those objects, taken in almost pitch-black conditions. They did this using a â€œdeep neural network,â€ a machine-learning technique that involves training a computer to associate certain inputs with specific outputs â€” in this case, dark, grainy images of transparent objects and the objects themselves.\r\n\r\nThe team trained a computer to recognize more than 10,000 transparent glass-like etchings, based on extremely grainy images of those patterns. The images were taken in very low lighting conditions, with about one photon per pixel â€” far less light than a camera would register in a dark, sealed room. They then showed the computer a new grainy image, not included in the training data, and found that it learned to reconstruct the transparent object that the darkness had obscured.\r\n\r\nThe results demonstrate that deep neural networks may be used to illuminate transparent features such as biological tissues and cells, in images taken with very little light.\r\n\r\n\r\nâ€œIn the lab, if you blast biological cells with light, you burn them, and there is nothing left to image,â€ says George Barbastathis, professor of mechanical engineering at MIT. â€œWhen it comes to X-ray imaging, if you expose a patient to X-rays, you increase the danger they may get cancer. What weâ€™re doing here is, you can get the same image quality, but with a lower exposure to the patient. And in biology, you can reduce the damage to biological specimens when you want to sample them.â€\r\n\r\n\r\nBarbastathisâ€™ co-authors on the paper are lead author Alexandre Goy, Kwabena Arthur, and Shuai Li.\r\n\r\nDeep dark learning\r\n\r\n\r\nNeural networks are computational schemes that are designed to loosely emulate the way the brainâ€™s neurons work together to process complex data inputs. A neural network works by performing successive â€œlayersâ€ of mathematical manipulations. Each computational layer calculates the probability for a given output, based on an initial input. For instance, given an image of a dog, a neural network may identify features reminiscent first of an animal, then more specifically a dog, and ultimately, a beagle. A â€œdeepâ€ neural network encompasses many, much more detailed layers of computation between input and output.\r\n\r\n\r\nA researcher can â€œtrainâ€ such a network to perform computations faster and more accurately, by feeding it hundreds or thousands of images, not just of dogs, but other animals, objects, and people, along with the correct label for each image. Given enough data to learn from, the neural network should be able to correctly classify completely new images.\r\n\r\nDeep neural networks have been widely applied in the field of computer vision and image recognition, and recently, Barbastathis and others developed neural networks to reconstruct transparent objects in images taken with plenty of light. Now his team is the first to use deep neural networks in experiments to reveal invisible objects in images taken in the dark.\r\n\r\nâ€œInvisible objects can be revealed in different ways, but it usually requires you to use ample light,â€ Barbastathis says. â€œWhat weâ€™re doing now is visualizing the invisible objects, in the dark. So itâ€™s like two difficulties combined. And yet we can still do the same amount of revelation.â€'),
(12, 3, 'Deep-learning technique reveals \"invisible\"objects in the dark', '2018-12-23 15:58:42', 'Lex Fridman', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science', 'pieter_Abbel.png', '\r\n  Small imperfections in a wine glass or tiny creases in a contact lens can be tricky to make out, even in good light. In almost total darkness, images of such transparent features or objects are nearly impossible to decipher. But now, engineers at MIT have developed a technique that can reveal these â€œinvisibleâ€ objects, in the dark.\r\n\r\n\r\nIn a study published today in Physical Review Letters, the researchers reconstructed transparent objects from images of those objects, taken in almost pitch-black conditions. They did this using a â€œdeep neural network,â€ a machine-learning technique that involves training a computer to associate certain inputs with specific outputs â€” in this case, dark, grainy images of transparent objects and the objects themselves.\r\n\r\nThe team trained a computer to recognize more than 10,000 transparent glass-like etchings, based on extremely grainy images of those patterns. The images were taken in very low lighting conditions, with about one photon per pixel â€” far less light than a camera would register in a dark, sealed room. They then showed the computer a new grainy image, not included in the training data, and found that it learned to reconstruct the transparent object that the darkness had obscured.\r\n\r\nThe results demonstrate that deep neural networks may be used to illuminate transparent features such as biological tissues and cells, in images taken with very little light.\r\n\r\n\r\nâ€œIn the lab, if you blast biological cells with light, you burn them, and there is nothing left to image,â€ says George Barbastathis, professor of mechanical engineering at MIT. â€œWhen it comes to X-ray imaging, if you expose a patient to X-rays, you increase the danger they may get cancer. What weâ€™re doing here is, you can get the same image quality, but with a lower exposure to the patient. And in biology, you can reduce the damage to biological specimens when you want to sample them.â€\r\n\r\n\r\nBarbastathisâ€™ co-authors on the paper are lead author Alexandre Goy, Kwabena Arthur, and Shuai Li.\r\n\r\nDeep dark learning\r\n\r\n\r\nNeural networks are computational schemes that are designed to loosely emulate the way the brainâ€™s neurons work together to process complex data inputs. A neural network works by performing successive â€œlayersâ€ of mathematical manipulations. Each computational layer calculates the probability for a given output, based on an initial input. For instance, given an image of a dog, a neural network may identify features reminiscent first of an animal, then more specifically a dog, and ultimately, a beagle. A â€œdeepâ€ neural network encompasses many, much more detailed layers of computation between input and output.\r\n\r\n\r\nA researcher can â€œtrainâ€ such a network to perform computations faster and more accurately, by feeding it hundreds or thousands of images, not just of dogs, but other animals, objects, and people, along with the correct label for each image. Given enough data to learn from, the neural network should be able to correctly classify completely new images.\r\n\r\nDeep neural networks have been widely applied in the field of computer vision and image recognition, and recently, Barbastathis and others developed neural networks to reconstruct transparent objects in images taken with plenty of light. Now his team is the first to use deep neural networks in experiments to reveal invisible objects in images taken in the dark.\r\n\r\nâ€œInvisible objects can be revealed in different ways, but it usually requires you to use ample light, Barbastathis says. â€œWhat weâ€™re doing now is visualizing the invisible objects, in the dark. So itâ€™s like two difficulties combined. And yet we can still do the same amount of revelation.â€\r\n'),
(13, 4, 'Airbus Defence and Space ', '2018-12-23 16:09:24', 'Mybridge John', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science, MIT, Lex Fridman,Andrew Ng, Keras,Theano', 'Airbus.png', '\r\n The Airbus Digital Transformation Office (DTO) is looking for a Data Scientist to join our Data Analytics, Apps and Services department in Toulouse.\r\n\r\nThe mission of the DTO inside Airbus Defence and Space is to actively support the business and help drive the transformation, and is articulated around the following objectives :\r\n\r\nContribute directly to strategic analytics programs and projects\r\n\r\nAssist in the definition and selection of key programs to drive forward lighthouse deliver examples\r\nDrive Airbus data strategy\r\n\r\nHelp define and drive Airbus data engineering strategy\r\n\r\nEnsure proper access to market best practices through structured and focused benchmarking or partnerships\r\n\r\nHelp establish a value proposition framework for digital initiatives, including appropriate new business models\r\n\r\nPromote and facilitate the portfolio of initiatives; capture lessons learnt to accelerate, scale-up and spread most promising projects beyond the current boundaries\r\n\r\nCoordinate across community of Airbus group digital stakeholders and connect teams in order to promote information and best practice sharing\r\n\r\nDrive and accompany business transformation in a digital environment\r\n\r\n\r\nYour main tasks and responsibilities will include :\r\n\r\nDesign, develop, test and deploy Data Science and AI solutions\r\n\r\nSupport teams and individuals across the business in identifying impactful opportunities for advanced analytics\r\n\r\nCommunicate outcomes to various project stakeholders, including senior management\r\n\r\nOwn, improve and promote best practices and scientific methods for ML, advanced statistics and predictive modeling.\r\n\r\nDevelop domain knowledge around the diverse portfolio of Airbus Defence and Space including Space Systems, Secure Communications, Military Aircraft, Digital Security and Intelligence as well as Unmanned Aerial Systems and Drones\r\n\r\nAbility to travel at least 25%\r\n\r\nThis job requires an awareness of any potential compliance risks and a commitment to act with integrity, as the foundation for the Companyâ€™s success, reputation and sustainable growth.\r\n\r\nCompÃ©tences requises\r\n\r\nYou will have the following skills and experience :\r\n\r\nMasters Degree or PhD degree in computer science, applied mathematics or a related field\r\n3+ years of proven experience as a Data Scientist\r\nCustomer focus experience delivering analytic capabilities in service to tangible business outcomes\r\nProficient programming skills in at least two of the following : Python, R, Scala or Java.\r\nExperience delivering within one of the sub-domains of analytics, such as machine learning, artificial intelligence, statistical analysis (GLM, Bayesian Models.'),
(15, 2, 'Best Know Algorithms in 2019', '2018-12-25 19:58:42', 'Lex Fridman', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science,MIT,Lex Fridman, Andrew Ng, Kears, Theano, FB,Google, Aws,Amazon', 'ai4.png', '\r\n Small imperfections in a wine glass or tiny creases in a contact lens can be tricky to make out, even in good light. In almost total darkness, images of such transparent features or objects are nearly impossible to decipher. But now, engineers at MIT have developed a technique that can reveal these â€œinvisibleâ€ objects, in the dark. In a study published today in Physical Review Letters, the researchers reconstructed transparent objects from images of those objects, taken in almost pitch-black conditions. They did this using a â€œdeep neural network,â€ a machine-learning technique that involves training a computer to associate certain inputs with specific outputs â€” in this case, dark, grainy images of transparent objects and the objects themselves. The team trained a computer to recognize more than 10,000 transparent glass-like etchings, based on extremely grainy images of those patterns. The images were taken in very low lighting conditions, with about one photon per pixel â€” far less light than a camera would register in a dark, sealed room. They then showed the computer a new grainy image, not included in the training data, and found that it learned to reconstruct the transparent object that the darkness had obscured. The results demonstrate that deep neural networks may be used to illuminate transparent features such as biological tissues and cells, in images taken with very little light. â€œIn the lab, if you blast biological cells with light, you burn them, and there is nothing left to image,â€ says George Barbastathis, professor of mechanical engineering at MIT. â€œWhen it comes to X-ray imaging, if you expose a patient to X-rays, you increase the danger they may get cancer. What weâ€™re doing here is, you can get the same image quality, but with a lower exposure to the patient. And in biology, you can reduce the damage to biological specimens when you want to sample them.â€ Barbastathisâ€™ co-authors on the paper are lead author Alexandre Goy, Kwabena Arthur, and Shuai Li. Deep dark learning Neural networks are computational schemes that are designed to loosely emulate the way the brainâ€™s neurons work together to process complex data inputs. A neural network works by performing successive â€œlayersâ€ of mathematical manipulations. Each computational layer calculates the probability for a given output, based on an initial input. For instance, given an image of a dog, a neural network may identify features reminiscent first of an animal, then more specifically a dog, and ultimately, a beagle. A â€œdeepâ€ neural network encompasses many, much more detailed layers of computation between input and output. A researcher can â€œtrainâ€ such a network to perform computations faster and more accurately, by feeding it hundreds or thousands of images, not just of dogs, but other animals, objects, and people, along with the correct label for each image. Given enough data to learn from, the neural network should be able to correctly classify completely new images. Deep neural networks have been widely applied in the field of computer vision and image recognition, and recently, Barbastathis and others developed neural networks to reconstruct transparent objects in images taken with plenty of light. Now his team is the first to use deep neural networks in experiments to reveal invisible objects in images taken in the dark. â€œInvisible objects can be revealed in different ways, but it usually requires you to use ample light,â€ Barbastathis says. â€œWhat weâ€™re doing now is visualizing the invisible objects, in the dark. So itâ€™s like two difficulties combined. And yet we can still do the same amount of revelation.â€'),
(16, 2, '2018 proved that computer vision is the most powerful manifestation of AI', '2018-12-26 19:46:59', 'Vivek Mohta', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science,MIT,Lex Fridman, Andrew Ng, Kears, Theano, FB,Google, Aws,Amazon', 'ai5.png', '\r\n  You probably use computer vision every day and donâ€™t even think about it. Enjoy checking out the latest Snapchat filters?Â Thatâ€™s computer vision. Unlock your iPhone with your face?Â Thatâ€™s computer vision, too. Use your phone to deposit your latest paycheck and get some cash in your bank account? Well,Â thatâ€™s also computer vision.\r\n\r\nComputer vision as we know it is at a tipping point. Thanks to industry-wide development efforts and advances in deep learning algorithms and graphics processors, weâ€™re doing things that were unimaginable just a decade ago.\r\n\r\nSome of the technology has been around for a few years, but a handful of developments in the past year have taken computer vision to new heights. The confluence of better sensors, a massive number of labeled images, easy access to deep learning software, and improved processors have combined to create functionality that was available only to a limited handful of large tech companies just a year ago.\r\n\r\nAmazon releasedÂ RekognitionÂ to put computer vision in the hands of any developer. Microsoft rolled out new AI services forÂ OneDrive and SharePoint. Google PhotosÂ makes our memories searchable\r\n\r\nIt would seem the future is imminent.\r\n\r\n\r\nA world of possibilities\r\n\r\nThe ambitious computer vision projects we have seen in 2018 signify that the technology is finally catching up with the applications that developers have long yearned to create. It also means that it will soon get cheaper to develop tailored computer vision applications.\r\n\r\nModiFace, for instance, lets users try on makeup using only their smartphones.Â TopologyÂ does the same for eyewear.Â MTailorÂ makes custom-tailored jeans and shirts using a similar process. Outside of fashion,Â Pottery BarnÂ lets users see what new furniture might look like in their homes, andÂ HoverÂ turns usersâ€™ pictures of their homes into fully measured 3D models.\r\n\r\nNone of these projects is as complicated asÂ self-driving carsÂ andÂ cashierless grocery stores,Â but thatâ€™s what qualifies the current generation of computer vision products as a harbinger for massive deployment in the next few years: Once it becomes possible for small companies to develop functioning computer vision products for a mass audience, the technology will begin infiltrating almost every part of our lives. \r\n\r\nWhat makes computer vision different\r\n\r\nComputer vision isnâ€™t like other AI technology. First, computer vision is an entirely new capability for most organizations, not an incremental improvement to something that others have tried before, like predictive analytics.\r\n\r\nAlso, there is no intrinsic barrier for computer vision improving toward human-level perception.Â When these algorithms infer information from images, theyâ€™re not trying to predict an intrinsically uncertain future, likeÂ lots of other AIÂ does; theyâ€™re just identifying a categorical truth about the present contents of an image or set of images. This means computer vision will be able to get more accurate over time until it matches â€” or exceeds â€” the abilities of human image recognition.\r\n\r\nFinally, computer vision can collectÂ training dataÂ much more quickly than other AI tools. Big data sets require massive investments in training data, but computer vision just needs people to label pictures and videos accurately â€” easy stuff. And thatâ€™s why computer visionâ€™s adoption rate has accelerated so much in the recent past.\r\n\r\nComputer vision in 2019 and beyond\r\n\r\nWhile weâ€™re already beginning to see computer vision pop up in consumer products, a sizable chunk of its uses will continue to be devoted to specific industry uses. For example, CCC Information Services is helping auto insurance companiesÂ identify vehicle damageÂ using heat maps that highlight where the worst damage occurs.\r\n\r\nThese types of computer vision products might be less glitzy, but itâ€™s important to remember that each new application means developers get more information about what works and what doesnâ€™t â€” and that continues to move us closer and closer to big-time projectsÂ like smart cities.\r\n\r\nThe recent leaps forward that Amazon, Microsoft, and Google showcased in 2018 have been the catalyst that will drive computer vision over the tipping point. Product designers and AI engineers are already working on new solutions that use computer vision and augmented reality. Hardware manufacturers are improving component performance and increasing cost efficiencies to make this technology better and more accessible.\r\n\r\nOne of the biggest near-future innovations will be about training data. Right now, humans still need to train computer vision AI with manually labeled images. (If youâ€™ve ever filled out a web form that required you to choose a few images from a grid showing a common object like a storefront or a car, youâ€™ve actually participated in creating labeled data for computer vision projects.)\r\n\r\nBut as the technology improves, AI willÂ learn to train AI, further streamlining the process and accelerating the rate of improvement.\r\n\r\nThe market for computer vision is growing almost as quickly as the capabilities: Itâ€™s projected to reachÂ $26.2 billionÂ by 2025, growing more than 30 percent per year. AI is the future, and computer vision is the most powerful manifestation of that future. Soon, it will be anywhere and everywhere â€” so much so that you wonâ€™t even notice it.\r\n\r\n\r\n');
INSERT INTO `posts` (`post_id`, `category_id`, `post_title`, `post_date`, `post_author`, `post_keywords`, `post_image`, `post_content`) VALUES
(17, 3, 'Eight Machine Learning JS Frameworks To Consider In 2019', '2018-12-26 20:01:02', 'Samaira Sandberg', 'Machine Learning, Data Science, Programming,Artificial Intelligence, Towards Data Science', 'ml7.png', '\r\n  There is a huge growth in machine learning development in the past few months. It is due to the availability of various open source tools that can create applications easily.- Natural language processing\r\n\r\nWhile the Python programming language feeds most machine learning frameworks, JavaScript has not lagged behind. This is the reason why JavaScript developers are using a number of frameworks for training and implementing machine learning models in the browser.\r\n\r\nIn this blog, we will discuss various top machine learning JavaScript frameworks that you must consider for your online business growth in 2019.\r\n\r\n1. Brain.js\r\n\r\nFor training Naive-Bayesian classifier and neural networks, this set of JavaScript libraries is used.\r\n\r\nTo set up Brain.js, use the following code:\r\n\r\n â€œnpm install brain.jsâ€\r\n\r\nHowever, to install the Naive Bayesian classifier, use the following code:\r\n\r\nâ€œnpm install classifierâ€\r\n\r\nYou can also include library in the browser using the code given below:\r\n\r\n<script src=â€https://raw.githubusercontent.com/harthur-org/brain.js/master/browser.js\"></script>\r\n\r\n2. ML-JS\r\n\r\n   To work with both NodeJS and browsers, it provides machine learning tools. First, you need to set up the ML JS tool using the following code:\r\n\r\n<script src=â€https://www.lactame.com/lib/ml/2.2.0/ml.min.js\"></script>\r\n\r\nHere, I have listed the machine learning algorithms which are supported:\r\n\r\n-> Supervised learning includes:\r\n\r\nK-Nearest Neighbor (KNN)\r\n\r\nSimple linear regression\r\n\r\nNaive Bayes\r\n\r\nRandom forest\r\n\r\nDecision tree: CART\r\n\r\nPartial least squares (PLS)\r\n\r\nLogistic regression\r\n\r\n-> Unsupervised learning includes:\r\n\r\nK-means clustering\r\n\r\nPrincipal component analysis (PCA)\r\n\r\nThis provides a collection of machine learning tools which work with browsers as well as NodeJS. It uses the\r\n\r\n3. KerasJS\r\n\r\nUsing KeraJS, you can easily run Keras models in the browser with support of GPU via WebGL. These models can also be run in Node.js but only in CPU mode.\r\n\r\nI have listed out some Keras models that can be run in theÂ browser:\r\n\r\n- Bidirectional LSTM for IMDB sentiment classification\r\n\r\n- DenseNet-121, trained on ImageNet\r\n\r\n- 50-layer residual network, trained on ImageNet\r\n\r\n- Convolutional variational autoencoder, trained on MNIST\r\n\r\n- Basic convnet for MNIST\r\n\r\n- Auxiliary classifier generative adversarial networks (AC-GAN) on MNIST\r\n\r\n- Inception v3, trained on ImageNet\r\n\r\n- SqueezeNet v1.1, trained on ImageNet\r\n\r\n4. Limdu.js\r\n\r\n It is a machine learning framework used for Node.js. By using the following command, you can install it:\r\nnpm install limdu\r\n\r\nIt supports some of the following:\r\n\r\n- Feature engineering\r\n\r\n- Binary classification\r\n\r\n- Multi-label classification\r\n\r\n- SVM\r\n\r\n5. DeepLearning.js\r\n\r\nIt is an open source machine learning JavaScript framework maintained by Google. It can be used for different purposes like understanding ML models, training neural networks in the browser, for educational purposes, etc.\r\n\r\nBy using this framework, you can run pre-trained models in an inference model. In fact, one can write the code in Typescript (ES6 JavaScript or ES5 JavaScript). Ypi can quickly start by including the following code within a header tag in the HTML file and writing JS programs to build the model.\r\n\r\n<script src=â€https://cdn.jsdelivr.net/npm/deeplearn@latest\"></script>\r\n\r\n or \r\n\r\n<script src=â€https://unpkg.com/deeplearn@latest\"></script>\r\n\r\n6. PropelJS\r\n\r\n  It is a machine learning JavaScript library that provides a numpy infrastructure backed by GPUs, especially for scientific computing. It can be used for both the browser and the NodeJS applications.\r\n\r\nThe following is the configuration code for the browser:\r\n\r\n<script src=â€https://unpkg.com/propel@3.1.0\"></script>\r\n\r\nFor a nodejs application, you need to use the following code:\r\n\r\nâ€œnpm install propelâ€\r\n\r\nâ€œimport { grad } from â€œpropelâ€;\r\n\r\n7. STDLib\r\n\r\n  To build advanced statistical models and machine learning libraries, this JavaScript library is used. IT can further be used for plotting and graphics functionality for exploratory data analysis and data visualization.\r\n\r\nIn relation to ML, the list of libraries is givenÂ below:\r\n\r\n- Binary classification via Stochastic gradient descent\r\n\r\nFor instance: @stdlib/ml/online-binary-classification\r\n\r\n- Linear regression via Stochastic gradient descent\r\n\r\nFor example: @stdlib/ml/online-sgd-regression\r\n\r\n- Natural language processing\r\n\r\nFor example: @stdlib/nlp\r\n\r\n8. ConvNetJS\r\n\r\n  This JavaScript library is used to train neural networks(deep learning models) entirely in the browser. The NodeJs app can use this library too. To start with it, you need to get its minified version using ConvNetJS minified library.\r\n\r\nUse the following code:\r\n\r\n<script src=â€convnet-min.jsâ€></script>\r\n\r\nConclusion:\r\n\r\nSo far we have seen the top 8 machine learning JavaScript frameworks which you must consider for your web development in 2019. Obviously, JavaScript is not becoming the language of choice for Machine Learning, far from it.\r\n\r\nHowever, common problems, such as performance, Matrix manipulations and the abundance of useful libraries, are slowly being overcome, closing the gap between common applications and using machine learning.\r\n\r\nHence, the above-listed machine learning JavaScript libraries will help you a lot for the good business growth. Moreover, I invite you to suggest more libraries or useful projects to monitor or those who have been working on yourselves, which can be added to the list.\r\n\r\n');

-- --------------------------------------------------------

--
-- Structure de la table `User_Sales`
--

CREATE TABLE `User_Sales` (
  `User_Sales_id` int(11) NOT NULL,
  `First_Name` varchar(100) NOT NULL,
  `Last_Name` varchar(100) NOT NULL,
  `Birth_date` text NOT NULL,
  `Gender` varchar(50) NOT NULL,
  `Join_Date` text NOT NULL,
  `Total_Sales` int(10) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

--
-- Déchargement des données de la table `User_Sales`
--

INSERT INTO `User_Sales` (`User_Sales_id`, `First_Name`, `Last_Name`, `Birth_date`, `Gender`, `Join_Date`, `Total_Sales`) VALUES
(1, 'Sophie', 'Lee', 'Jan-05-1960', 'F', 'Apr-05-2015', 500),
(2, 'Richard', 'Brown', 'Jan-07-1975', 'M', 'Apr-05-2015', 200),
(3, 'Jamal', 'Santo', 'Oct-08-1983', 'M', 'Apr-09-2015', 350),
(4, 'Casey', 'Healy', 'Sep-20-1969', 'M', 'Apr-09-2015', 80),
(5, 'Jill', 'Wilkes', 'Nov-20-1979', 'F', 'Apr-15-2015', 210);

--
-- Index pour les tables déchargées
--

--
-- Index pour la table `admin_users`
--
ALTER TABLE `admin_users`
  ADD PRIMARY KEY (`user_id`);

--
-- Index pour la table `categories`
--
ALTER TABLE `categories`
  ADD PRIMARY KEY (`cat_id`);

--
-- Index pour la table `comments`
--
ALTER TABLE `comments`
  ADD PRIMARY KEY (`comment_id`);

--
-- Index pour la table `posts`
--
ALTER TABLE `posts`
  ADD PRIMARY KEY (`post_id`);

--
-- Index pour la table `User_Sales`
--
ALTER TABLE `User_Sales`
  ADD PRIMARY KEY (`User_Sales_id`);

--
-- AUTO_INCREMENT pour les tables déchargées
--

--
-- AUTO_INCREMENT pour la table `admin_users`
--
ALTER TABLE `admin_users`
  MODIFY `user_id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=3;
--
-- AUTO_INCREMENT pour la table `categories`
--
ALTER TABLE `categories`
  MODIFY `cat_id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=7;
--
-- AUTO_INCREMENT pour la table `comments`
--
ALTER TABLE `comments`
  MODIFY `comment_id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=14;
--
-- AUTO_INCREMENT pour la table `posts`
--
ALTER TABLE `posts`
  MODIFY `post_id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=18;
--
-- AUTO_INCREMENT pour la table `User_Sales`
--
ALTER TABLE `User_Sales`
  MODIFY `User_Sales_id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=6;COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
